{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'with mask', 1: 'without mask'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file='dataset'\n",
    "path=os.listdir(file)\n",
    "categories=[i for i in range(len(path))]\n",
    "dictonary={i:j for i,j in enumerate(path)}\n",
    "dictonary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "labels=[]\n",
    "for category in categories:\n",
    "    file_path=os.path.join(file,dictonary[category])\n",
    "    image_path=os.listdir(file_path)\n",
    "    for i,j in enumerate(image_path):\n",
    "        images=os.path.join(file_path,image_path[i])\n",
    "        grey_img=cv2.cvtColor(cv2.imread(images),cv2.COLOR_BGR2GRAY)\n",
    "        resized=cv2.resize(grey_img,(100,100))\n",
    "        data.append(resized)\n",
    "        labels.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data=np.array(data,'float32')/255\n",
    "data=np.array(data,'float32').reshape(data.shape[0],100,100,1)\n",
    "labels=keras.utils.to_categorical(labels,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation,Flatten,Dropout,MaxPooling2D,Convolution2D,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Convolution2D(200,3,activation='relu',input_shape=data.shape[1:]))\n",
    "model.add(MaxPooling2D((2,2),2))\n",
    "\n",
    "model.add(Convolution2D(100,3,activation='relu',input_shape=data.shape[1:]))\n",
    "model.add(MaxPooling2D((2,2),2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "          \n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_y,test_x,test_y=train_test_split(data,labels,test_size=0.1,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "35/35 [==============================] - 64s 2s/step - loss: 0.7302 - accuracy: 0.5173 - val_loss: 0.6467 - val_accuracy: 0.6123\n",
      "Epoch 2/20\n",
      "35/35 [==============================] - 63s 2s/step - loss: 0.5753 - accuracy: 0.7173 - val_loss: 0.4403 - val_accuracy: 0.8225\n",
      "Epoch 3/20\n",
      "35/35 [==============================] - 64s 2s/step - loss: 0.3715 - accuracy: 0.8518 - val_loss: 0.3521 - val_accuracy: 0.8478\n",
      "Epoch 4/20\n",
      "35/35 [==============================] - 66s 2s/step - loss: 0.2838 - accuracy: 0.8818 - val_loss: 0.3472 - val_accuracy: 0.8261\n",
      "Epoch 5/20\n",
      "35/35 [==============================] - 64s 2s/step - loss: 0.2294 - accuracy: 0.9118 - val_loss: 0.2528 - val_accuracy: 0.9022\n",
      "Epoch 6/20\n",
      "35/35 [==============================] - 64s 2s/step - loss: 0.1661 - accuracy: 0.9373 - val_loss: 0.2640 - val_accuracy: 0.8986\n",
      "Epoch 7/20\n",
      "35/35 [==============================] - 64s 2s/step - loss: 0.1320 - accuracy: 0.9518 - val_loss: 0.1772 - val_accuracy: 0.9167\n",
      "Epoch 8/20\n",
      "35/35 [==============================] - 64s 2s/step - loss: 0.0868 - accuracy: 0.9709 - val_loss: 0.1780 - val_accuracy: 0.9239\n",
      "Epoch 9/20\n",
      "35/35 [==============================] - 64s 2s/step - loss: 0.0642 - accuracy: 0.9791 - val_loss: 0.1692 - val_accuracy: 0.9601\n",
      "Epoch 10/20\n",
      "35/35 [==============================] - 64s 2s/step - loss: 0.0517 - accuracy: 0.9764 - val_loss: 0.2256 - val_accuracy: 0.9239\n",
      "Epoch 11/20\n",
      "35/35 [==============================] - 71s 2s/step - loss: 0.0659 - accuracy: 0.9773 - val_loss: 0.3261 - val_accuracy: 0.8986\n",
      "Epoch 12/20\n",
      "35/35 [==============================] - 67s 2s/step - loss: 0.0581 - accuracy: 0.9782 - val_loss: 0.1998 - val_accuracy: 0.9312\n",
      "Epoch 13/20\n",
      "35/35 [==============================] - 64s 2s/step - loss: 0.0544 - accuracy: 0.9782 - val_loss: 0.2383 - val_accuracy: 0.9239\n",
      "Epoch 14/20\n",
      "35/35 [==============================] - 64s 2s/step - loss: 0.0462 - accuracy: 0.9882 - val_loss: 0.2050 - val_accuracy: 0.9312\n",
      "Epoch 15/20\n",
      "35/35 [==============================] - 66s 2s/step - loss: 0.0267 - accuracy: 0.9936 - val_loss: 0.2164 - val_accuracy: 0.9529\n",
      "Epoch 16/20\n",
      "35/35 [==============================] - 64s 2s/step - loss: 0.0272 - accuracy: 0.9918 - val_loss: 0.2632 - val_accuracy: 0.9457\n",
      "Epoch 17/20\n",
      "35/35 [==============================] - 65s 2s/step - loss: 0.0279 - accuracy: 0.9900 - val_loss: 0.3146 - val_accuracy: 0.9167\n",
      "Epoch 18/20\n",
      "35/35 [==============================] - 64s 2s/step - loss: 0.0445 - accuracy: 0.9827 - val_loss: 0.2445 - val_accuracy: 0.9457\n",
      "Epoch 19/20\n",
      "35/35 [==============================] - 64s 2s/step - loss: 0.0319 - accuracy: 0.9882 - val_loss: 0.3634 - val_accuracy: 0.9167\n",
      "Epoch 20/20\n",
      "35/35 [==============================] - 64s 2s/step - loss: 0.0213 - accuracy: 0.9945 - val_loss: 0.2390 - val_accuracy: 0.9565\n"
     ]
    }
   ],
   "source": [
    "hiss=model.fit(train_x,test_x,epochs=20,validation_data=(train_y,test_y),validation_split=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_json=model.to_json()\n",
    "with open ('fin.json','w') as json_file:\n",
    "    json_file.write(fin_json)\n",
    "model.save_weights('fe.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.preprocessing import image as img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model_from_json(open('fin.json','r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 4s 445ms/step - loss: 0.2390 - accuracy: 0.9565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2389936000108719, 0.95652174949646]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_y,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('fe.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255, 0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_cls=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cap=cv2.VideoCapture(0)\n",
    "ma={0:'Mask',1:'No Mask'}\n",
    "color={0:(0,255,0),1:(0,0,255)}\n",
    "color[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    grey_img=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    face=face_cls.detectMultiScale(grey_img,1.3,5)\n",
    "    for (x,y,w,h) in face:\n",
    "        cropped_img=frame[x:x+w,y:y+h]\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        grey_cropped=cv2.cvtColor(cropped_img,cv2.COLOR_BGR2GRAY)\n",
    "        resized=cv2.resize(grey_cropped,(100,100))\n",
    "        samples=img.img_to_array(resized)\n",
    "        samples=np.array(samples/255.0,'float32').reshape(1,100,100,1)\n",
    "        prediction=model.predict(samples)\n",
    "        index=np.argmax(prediction[0])\n",
    "        cv2.putText(frame,ma[index],(x,y-9),cv2.FONT_ITALIC,1,color[index],2)\n",
    "        cv2.imshow('face',frame)\n",
    "    if cv2.waitKey(10)==13:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
